{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.71%\n",
      "Training Size: 50, Test Accuracy: 89.55%\n",
      "Training Size: 100, Test Accuracy: 96.03%\n",
      "Training Size: 200, Test Accuracy: 98.09%\n",
      "Training Size: 300, Test Accuracy: 97.56%\n",
      "Training Size: 500, Test Accuracy: 98.38%\n",
      "Training Size: 1000, Test Accuracy: 98.71%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(69)\n",
    "\n",
    "def get_data(N = 300):\n",
    "    X = np.random.randn(N, 2)\n",
    "    T = np.where(X[:, 0]**2 + X[:, 1]**2 < 1.0, 0, 1)\n",
    "    Y = np.zeros((N, 1))\n",
    "    Y[T == 1] = 1\n",
    "    return X, Y\n",
    "\n",
    "class NN():\n",
    "    def __init__(self, architecture):\n",
    "        self.activations = []\n",
    "        self.params_values = {}\n",
    "        self.layers = len(architecture)\n",
    "        self.grads_momentum = {}\n",
    "        for i, layer in enumerate(architecture):\n",
    "            input_size, output_size, activation = layer[\"input_dim\"], layer[\"output_dim\"], layer[\"activation\"]\n",
    "            self.activations.append(activation)\n",
    "            self.params_values[f\"W{str(i)}\"] = np.random.randn(\n",
    "                output_size, input_size\n",
    "            ) / np.sqrt(input_size)\n",
    "            self.params_values[f\"b{str(i)}\"] = np.zeros((1, output_size))\n",
    "            self.grads_momentum[f\"W{str(i)}\"] = np.zeros_like(self.params_values[f\"W{str(i)}\"])\n",
    "            self.grads_momentum[f\"b{str(i)}\"] = np.zeros_like(self.params_values[f\"b{str(i)}\"])\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.cache = {}\n",
    "        self.grads = {}\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def drelu(self, dA, z):\n",
    "        dA_ = np.copy(dA)\n",
    "        dA_[z <= 0] = 0\n",
    "        return dA_\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def dsigmoid(self, dA, z):\n",
    "        s = self.sigmoid(z)\n",
    "        return s * (1. - s) * dA\n",
    "\n",
    "    def bce(self, yhat, y):\n",
    "        yhat, y = yhat.flatten(), y.flatten()\n",
    "        cost = -np.mean(np.dot(y, np.log(yhat+1e-8)) + np.dot((1 - y), np.log(1 - yhat+1e-8)))\n",
    "        return np.squeeze(cost)\n",
    "\n",
    "    def dbce(self, yhat, y):\n",
    "        return -(y / (yhat+1e-8) - (1 - y) / (1 - yhat+1e-8))\n",
    "\n",
    "    def single_forward(self, x, W, b, activation):\n",
    "        Z = x @ W.T + b\n",
    "        A = getattr(self, activation)(Z)\n",
    "        return A, Z\n",
    "\n",
    "    def forward(self, x):\n",
    "        A_prev = None\n",
    "        A_curr = x\n",
    "        for i in range(self.layers):\n",
    "            W, b = self.params_values[f\"W{str(i)}\"], self.params_values[f\"b{str(i)}\"]\n",
    "            activation = self.activations[i]\n",
    "            A_prev = A_curr\n",
    "            A_curr, Z_curr = self.single_forward(A_prev, W, b, activation)\n",
    "            self.cache[str(i)] = (Z_curr, A_prev)\n",
    "        return A_curr\n",
    "\n",
    "    def single_backward(self, dA_curr, W, Z_curr, A_prev, activation):\n",
    "        m = A_prev.shape[1]\n",
    "        dactivation = getattr(self, f\"d{activation}\")\n",
    "        dA_curr = dactivation(dA_curr, Z_curr)\n",
    "        dW = np.dot(dA_curr.T, A_prev) / m\n",
    "        db = np.sum(dA_curr, axis = 0, keepdims = True) / m\n",
    "        dA_curr = np.dot(dA_curr, W)\n",
    "        return dA_curr, dW, db\n",
    "\n",
    "    def backward(self, yhat, y):\n",
    "        dA_curr = self.dbce(yhat, y)\n",
    "        for i in range(self.layers - 1, -1, -1):\n",
    "            W = self.params_values[f\"W{str(i)}\"]\n",
    "            Z_curr, A_prev = self.cache[str(i)]\n",
    "            dA_curr, dW, db = self.single_backward(dA_curr, W, Z_curr, A_prev, self.activations[i])\n",
    "            self.grads[f\"W{str(i)}\"] = dW\n",
    "            self.grads[f\"b{str(i)}\"] = db\n",
    "\n",
    "    def accuracy(self, yhat, y):\n",
    "        prediction = np.where(yhat > 0.5, 1, 0)\n",
    "        return np.mean(prediction == y)\n",
    "\n",
    "    def train(self, x, y, learning_rate, epochs, momentum = 0.9, weight_decay = 0.0001):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for _ in range(epochs):\n",
    "            yhat = self.forward(x)\n",
    "            loss = self.bce(yhat, y)\n",
    "            losses.append(loss)\n",
    "            accuracy = self.accuracy(yhat, y)\n",
    "            accuracies.append(accuracy)\n",
    "            self.backward(yhat, y)\n",
    "            self.update_params(weight_decay, momentum, learning_rate)\n",
    "\n",
    "        return losses, accuracies\n",
    "\n",
    "    def update_params(self, weight_decay, momentum, learning_rate):\n",
    "        for i in range(self.layers):\n",
    "            dW = self.grads[f\"W{str(i)}\"] + weight_decay * self.params_values[f\"W{str(i)}\"]\n",
    "            db = self.grads[f\"b{str(i)}\"] + weight_decay * self.params_values[f\"b{str(i)}\"]\n",
    "            self.grads_momentum[f\"W{str(i)}\"] = momentum * self.grads_momentum[f\"W{str(i)}\"] + (1 - momentum) * dW\n",
    "            self.grads_momentum[f\"b{str(i)}\"] = momentum * self.grads_momentum[f\"b{str(i)}\"] + (1 - momentum) * db\n",
    "            self.params_values[f\"W{str(i)}\"] -= learning_rate * self.grads_momentum[f\"W{str(i)}\"]\n",
    "            self.params_values[f\"b{str(i)}\"] -= learning_rate * self.grads_momentum[f\"b{str(i)}\"]\n",
    "        self.reset()\n",
    "\n",
    "X, Y = get_data(100)\n",
    "\n",
    "theta = np.linspace(0, 2*np.pi, 300)\n",
    "plt.plot(np.cos(theta), np.sin(theta), 'k--')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap='RdBu')\n",
    "plt.savefig('data.png')\n",
    "plt.close()\n",
    "        \n",
    "nn_architecture = [\n",
    "    {\"input_dim\": 2, \"output_dim\": 6, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 6, \"output_dim\": 3, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 3, \"output_dim\": 10, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 10, \"output_dim\": 4, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 4, \"output_dim\": 1, \"activation\": \"sigmoid\"},\n",
    "]\n",
    "\n",
    "nn = NN(nn_architecture)\n",
    "losses, accuracies = nn.train(X, Y, 0.005, 1000, 0.9, 0.1)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('loss.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('accuracy.png')\n",
    "plt.close()\n",
    "\n",
    "X_test, Y_test = get_data(100000)\n",
    "\n",
    "yhat = nn.forward(X_test)\n",
    "yhat = (yhat > 0.5).astype(int)\n",
    "accuracy = np.mean(yhat == Y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "theta = np.linspace(0, 2*np.pi, 360)\n",
    "plt.plot(np.cos(theta), np.sin(theta), 'k--')\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=yhat.flatten(), s=50, cmap='RdBu')\n",
    "plt.savefig('decision_boundary.png')\n",
    "plt.close()\n",
    "\n",
    "training_sizes = [50, 100, 200, 300, 500, 1000]\n",
    "test_accuracies = []\n",
    "\n",
    "for size in training_sizes:\n",
    "    X_train, Y_train = get_data(size)\n",
    "    nn = NN(nn_architecture)\n",
    "    nn.train(X_train, Y_train, 0.005, 1000, 0.9, 0.1)\n",
    "    yhat_test = nn.forward(X_test)\n",
    "    yhat_test = (yhat_test > 0.5).astype(int)\n",
    "    test_accuracy = np.mean(yhat_test == Y_test)\n",
    "    test_accuracies.append(test_accuracy * 100)\n",
    "    print(f\"Training Size: {size}, Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "plt.plot(training_sizes, test_accuracies, marker='o')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy vs. Training Size')\n",
    "plt.savefig('accuracy_vs_training_size.png')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
